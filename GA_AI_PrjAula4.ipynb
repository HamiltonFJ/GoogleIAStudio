{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOtdtKsz9E2ET6xXqMVC0gY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HamiltonFJ/GoogleIAStudio/blob/main/GA_AI_PrjAula4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalando o SDK Google"
      ],
      "metadata": {
        "id": "HO5D5YFPZZW0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVy9hDXvY3Vg"
      },
      "outputs": [],
      "source": [
        "!pip install -qU google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Python SDK\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Replace with your API key\n",
        "GOOGLE_API_KEY = \"AIzaSyB7EeYVs_HOlxyTfrYwlyYsZiTUslQz11Y\"\n",
        "\n",
        "# Configure the API key\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "FB-WOBAjZsgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Listar os Modelos disponíveis"
      ],
      "metadata": {
        "id": "XUK9_LG2aFYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for m in genai.list_models():\n",
        "    if 'generateContent' in m.supported_generation_methods:\n",
        "        print(m.name)"
      ],
      "metadata": {
        "id": "BAJR4E_WaCqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configurações: Nº respostas,Temperatura, Safety  "
      ],
      "metadata": {
        "id": "-2HztAIci1yW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generation_config = {\n",
        "  \"candidate_count\": 1,\n",
        "  \"temperature\": 0.5,\n",
        "}\n",
        "\n",
        "safety_settings = {\n",
        "  \"HARASSMENT\": \"BLOCK_NONE\",\n",
        "  \"HATE\": \"BLOCK_NONE\",\n",
        "  \"SEXUAL\": \"BLOCK_NONE\",\n",
        "  \"DANGEROUS\": \"BLOCK_NONE\"\n",
        "}"
      ],
      "metadata": {
        "id": "dKgVIJTna0xC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inicializar o modelo"
      ],
      "metadata": {
        "id": "M_3Z-qIvbRV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(model_name=\"gemini-pro\",\n",
        "                              generation_config=generation_config,\n",
        "                              safety_settings=safety_settings)\n",
        "response = model.generate_content(\"Vamos aprender conteúdo sobre IA. Me dê sugestões.\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "m182zEzcbVTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Armazena o histórico do chat"
      ],
      "metadata": {
        "id": "jNMXnuHfiTAg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "varchat = model.start_chat(history=[])"
      ],
      "metadata": {
        "id": "2Wub0KVJf49m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exibir o histórico (Config.Estética)"
      ],
      "metadata": {
        "id": "4pLuIkF7jk-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "def to_markdown(text):\n",
        "  \"\"\"Helper function to format text to markdown\"\"\"\n",
        "  text = text.replace(\"`\", \"'\")\n",
        "  return Markdown(textwrap.indent(text, \"  > \"))\n",
        "\n",
        "# print histórico\n",
        "for message in varchat.history:\n",
        "  display(to_markdown(f\"**{message.role}:** {message.parts[0].text}\"))\n",
        "print(\"---------------------------------------------------------\")"
      ],
      "metadata": {
        "id": "sHWb3O8ejpY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Executa o prompt enquanto a resposta não for \"fim\""
      ],
      "metadata": {
        "id": "QtULTK61nBk5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "def to_markdown(text):\n",
        "  \"\"\"Helper function to format text to markdown\"\"\"\n",
        "  text = text.replace(\"`\", \"'\")\n",
        "  return Markdown(textwrap.indent(text, \"  > \"))\n",
        "\n",
        "varchat = model.start_chat(history=[])  # Assumindo que você já iniciou o chat\n",
        "\n",
        "while True:\n",
        "    prompt = input(\"Prompt: \")\n",
        "    if prompt == \"fim\":\n",
        "        break\n",
        "\n",
        "    response = varchat.send_message(prompt)\n",
        "\n",
        "    # Formatação Markdown - Saída\n",
        "    display(to_markdown(f\"**Você:** {prompt}\"))\n",
        "    display(to_markdown(f\"**Gemini:** {response.text}\"))\n",
        "\n",
        "    print(\"-------------------------------------------------------------------\")"
      ],
      "metadata": {
        "id": "VVk-DICMmnIJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}